Our sincere thanks go to the competition organizers for their hard work and for providing such a valuable opportunity.
<p align="center"><img src="https://escalator.sadilar.org/post/2024/02/zindi/featured.png"/><img src="./img/organizations.png"/></p>

This work would not have been possible without these excellent resources made available to everyone.

- [How to Set Up and Run Qwen 3 Locally With Ollama](https://www.datacamp.com/tutorial/qwen3-ollama)
<p align="center"><img src="https://media.licdn.com/dms/image/v2/D5612AQEGf-_6HHqxmQ/article-cover_image-shrink_720_1280/B56ZhqLjqUG4AM-/0/1754128072027?e=2147483647&v=beta&t=tnICIFVudJLg78GJMH8uVoD8Jx1JQOub5NsfggpPn9E" width=550 height=250/></p>

- [Easily fine-tune & train LLMs, Get faster with unsloth](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2.5_(7B)-Alpaca.ipynb)
<p align="center"><img src="https://unsloth.ai/docs/~gitbook/image?url=https%3A%2F%2F3215535692-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FxhOjnexMCB3dmuQFQ2Zq%252Fuploads%252FICSa2F6HWtYJgUWiArtd%252F3x%2520faster%2520training.png%3Falt%3Dmedia%26token%3D2498e2fa-a74e-4298-95eb-55b706f577a3&width=490&dpr=3&quality=100&sign=c4118d10&sv=2" width=550 height=250/></p>

- [vLLM - Easy, fast, and cheap LLM serving for everyone](https://docs.vllm.ai/en/latest/serving/offline_inference/#ray-data-llm-api)
<p align="center"><img src="https://images.cloudclusters.io/897b2314d9c243628047742ac3ceedcb/vllm.png" width=550 height=250 /></p>

- [Kaggle, Your Home for Data Science](https://docs.vllm.ai/en/latest/serving/offline_inference/#ray-data-llm-api)
<p align="center"><img src="https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F19517213%2F6675ca9c08104304b8f69f5a71460e1d%2Fkaggle-update.png?generation=1711442408784693&alt=media" width=550 height=250 /></p>

- [Colab is a hosted Jupyter Notebook service that requires no setup to use and provides free access to computing resources, including GPUs and TPUs.](https://colab.google/)
<p align="center"><img src="https://algotrading101.com/learn/wp-content/uploads/2021/05/Google-Colab-Guide-e1620759490851.jpg" width=550 height=250 /></p>

- [ðŸ’« IntelÂ® LLM Library for PyTorch*](https://github.com/intel/ipex-llm)
<p align="center"><img src="https://external-preview.redd.it/ipex-llm-a-pytorch-library-for-running-llm-on-intel-cpu-and-v0-6xKiaZ4V9vQdGKwPrw61YXSXEy7UAMxY6K1KhuElMRw.jpg?width=1080&crop=smart&auto=webp&s=adfaa7aab82470c369fa71f9c03cc9b9fe935800" width=550 height=250 /></p>